---
# PyLama Tests
# Tests all PyLama-related endpoints in APILama

- name: Test PyLama Health Endpoint
  uri:
    url: "{{ api_base_url }}/api/pylama/health"
    method: GET
    return_content: yes
    status_code: [200, 503, 404]  # Accept 503/404 for service unavailable
  register: pylama_health_result
  failed_when: pylama_health_result.status == 200 and pylama_health_result.json.status != "ok"
  ignore_errors: yes  # Continue even if PyLama is not available

- name: Display PyLama Health Result
  debug:
    var: pylama_health_result.json
  when: pylama_health_result is defined

- name: Test PyLama Models Endpoint
  uri:
    url: "{{ api_base_url }}/api/pylama/models"
    method: GET
    return_content: yes
    status_code: [200, 503, 404]  # Accept 503/404 for service unavailable
  register: pylama_models_result
  failed_when: pylama_models_result.status == 200 and pylama_models_result.json.status != "success"
  ignore_errors: yes  # Continue even if PyLama is not available

- name: Display PyLama Models Result
  debug:
    var: pylama_models_result.json
  when: pylama_models_result is defined

- name: Test PyLama Execute Endpoint - Simple Query
  uri:
    url: "{{ api_base_url }}/api/pylama/execute"
    method: POST
    body_format: json
    body:
      model: "{{ lookup('env', 'OLLAMA_MODEL') | default('llama2', true) }}"
      query: "What is Python?"
      options:
        max_tokens: 100
        temperature: 0.7
    status_code: [200, 503, 404]  # Accept 503/404 for service unavailable
  register: pylama_execute_result
  failed_when: pylama_execute_result.status == 200 and pylama_execute_result.json.status != "success"
  ignore_errors: yes  # Continue even if PyLama is not available

- name: Display PyLama Execute Result
  debug:
    var: pylama_execute_result.json
  when: pylama_execute_result is defined

- name: Test PyLama Execute Endpoint - Code Analysis
  uri:
    url: "{{ api_base_url }}/api/pylama/execute"
    method: POST
    body_format: json
    body:
      model: "{{ lookup('env', 'OLLAMA_MODEL') | default('llama2', true) }}"
      query: "Analyze this code: def factorial(n): return 1 if n <= 1 else n * factorial(n-1)"
      options:
        max_tokens: 200
        temperature: 0.5
    status_code: [200, 503, 404]  # Accept 503/404 for service unavailable
  register: pylama_code_result
  failed_when: pylama_code_result.status == 200 and pylama_code_result.json.status != "success"
  ignore_errors: yes  # Continue even if PyLama is not available

- name: Display PyLama Code Analysis Result
  debug:
    var: pylama_code_result.json
  when: pylama_code_result is defined
